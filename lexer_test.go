package markit

import (
	"testing"
)

// TestLexerBasicFunctionality æµ‹è¯•è¯æ³•åˆ†æå™¨çš„åŸºæœ¬åŠŸèƒ½
func TestLexerBasicFunctionality(t *testing.T) {
	tests := []struct {
		name     string
		input    string
		expected []TokenType
	}{
		{
			name:     "Simple tag",
			input:    "<div>content</div>",
			expected: []TokenType{TokenOpenTag, TokenText, TokenCloseTag, TokenEOF},
		},
		{
			name:     "Self-closing tag",
			input:    "<img />",
			expected: []TokenType{TokenSelfCloseTag, TokenEOF},
		},
		{
			name:     "Comment",
			input:    "<!-- comment -->",
			expected: []TokenType{TokenComment, TokenEOF},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			lexer := NewLexer(tt.input)

			for i, expectedType := range tt.expected {
				token := lexer.NextToken()
				if token.Type != expectedType {
					t.Errorf("token %d: expected type %v, got %v", i, expectedType, token.Type)
				}
			}
		})
	}
}

// TestLexerPositionTracking æµ‹è¯•è¯æ³•åˆ†æå™¨çš„ä½ç½®è·Ÿè¸ª
func TestLexerPositionTracking(t *testing.T) {
	input := `<div>
	<span>text</span>
</div>`

	lexer := NewLexer(input)

	// ç¬¬ä¸€ä¸ªtokenåº”è¯¥åœ¨ç¬¬1è¡Œç¬¬1åˆ—
	token := lexer.NextToken()
	if token.Position.Line != 1 || token.Position.Column != 1 {
		t.Errorf("expected position (1,1), got (%d,%d)", token.Position.Line, token.Position.Column)
	}

	// ç»§ç»­è¯»å–tokenså¹¶éªŒè¯ä½ç½®
	for token.Type != TokenEOF {
		token = lexer.NextToken()
		// éªŒè¯ä½ç½®ä¿¡æ¯å­˜åœ¨ä¸”åˆç†
		if token.Position.Line < 1 || token.Position.Column < 1 {
			t.Errorf("invalid position (%d,%d) for token %v", token.Position.Line, token.Position.Column, token.Type)
		}
	}
}

// TestLexerAttributeParsing æµ‹è¯•å±æ€§è§£æ
func TestLexerAttributeParsing(t *testing.T) {
	tests := []struct {
		name       string
		input      string
		tagName    string
		attributes map[string]string
	}{
		{
			name:    "Single attribute",
			input:   `<div class="container">`,
			tagName: "div",
			attributes: map[string]string{
				"class": "container",
			},
		},
		{
			name:    "Multiple attributes",
			input:   `<img src="image.jpg" alt="description" width="100">`,
			tagName: "img",
			attributes: map[string]string{
				"src":   "image.jpg",
				"alt":   "description",
				"width": "100",
			},
		},
		{
			name:    "Boolean attribute",
			input:   `<input type="checkbox" checked>`,
			tagName: "input",
			attributes: map[string]string{
				"type":    "checkbox",
				"checked": "",
			},
		},
		{
			name:    "Single quoted attributes",
			input:   `<div class='container' id='main'>`,
			tagName: "div",
			attributes: map[string]string{
				"class": "container",
				"id":    "main",
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			lexer := NewLexer(tt.input)
			token := lexer.NextToken()

			if token.Type != TokenOpenTag && token.Type != TokenSelfCloseTag {
				t.Fatalf("expected tag token, got %v", token.Type)
			}

			if token.Value != tt.tagName {
				t.Errorf("expected tag name %q, got %q", tt.tagName, token.Value)
			}

			if len(token.Attributes) != len(tt.attributes) {
				t.Errorf("expected %d attributes, got %d", len(tt.attributes), len(token.Attributes))
			}

			for key, expectedValue := range tt.attributes {
				if actualValue, exists := token.Attributes[key]; !exists {
					t.Errorf("missing attribute %q", key)
				} else if actualValue != expectedValue {
					t.Errorf("attribute %q: expected %q, got %q", key, expectedValue, actualValue)
				}
			}
		})
	}
}

// TestLexerCommentParsing æµ‹è¯•æ³¨é‡Šè§£æ
func TestLexerCommentParsing(t *testing.T) {
	tests := []struct {
		name     string
		input    string
		expected string
	}{
		{
			name:     "Simple comment",
			input:    "<!-- Hello World -->",
			expected: "Hello World",
		},
		{
			name:     "Comment with special characters",
			input:    "<!-- <script>alert('test');</script> -->",
			expected: "<script>alert('test');</script>",
		},
		{
			name:     "Multiline comment",
			input:    "<!-- Line 1\nLine 2\nLine 3 -->",
			expected: "Line 1\nLine 2\nLine 3",
		},
		{
			name:     "Empty comment",
			input:    "<!---->",
			expected: "",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			lexer := NewLexer(tt.input)
			token := lexer.NextToken()

			if token.Type != TokenComment {
				t.Fatalf("expected comment token, got %v", token.Type)
			}

			if token.Value != tt.expected {
				t.Errorf("expected comment %q, got %q", tt.expected, token.Value)
			}
		})
	}
}

// TestLexerTextParsing æµ‹è¯•æ–‡æœ¬è§£æ
func TestLexerTextParsing(t *testing.T) {
	tests := []struct {
		name     string
		input    string
		expected string
	}{
		{
			name:     "Simple text",
			input:    "Hello World",
			expected: "Hello World",
		},
		{
			name:     "Text with whitespace",
			input:    "  Hello   World  ",
			expected: "Hello   World",
		},
		{
			name:     "Text with special characters",
			input:    "Hello & World Â© 2023",
			expected: "Hello & World Â© 2023",
		},
		{
			name:     "Unicode text",
			input:    "ä½ å¥½ä¸–ç•Œ ğŸŒ",
			expected: "ä½ å¥½ä¸–ç•Œ ğŸŒ",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			lexer := NewLexer(tt.input)
			token := lexer.NextToken()

			if token.Type != TokenText {
				t.Fatalf("expected text token, got %v", token.Type)
			}

			if token.Value != tt.expected {
				t.Errorf("expected text %q, got %q", tt.expected, token.Value)
			}
		})
	}
}

// TestLexerErrorHandling æµ‹è¯•é”™è¯¯å¤„ç†
func TestLexerErrorHandling(t *testing.T) {
	tests := []struct {
		name  string
		input string
	}{
		{
			name:  "Unterminated tag",
			input: "<div",
		},
		{
			name:  "Invalid tag name",
			input: "<123invalid>",
		},
		{
			name:  "Unterminated attribute value",
			input: `<div class="unterminated`,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			lexer := NewLexer(tt.input)

			// è¯»å–æ‰€æœ‰tokensï¼Œç¡®ä¿ä¸ä¼šå´©æºƒ
			for {
				token := lexer.NextToken()
				if token.Type == TokenEOF || token.Type == TokenError {
					break
				}
			}

			// å¦‚æœåˆ°è¾¾è¿™é‡Œï¼Œè¯´æ˜æ²¡æœ‰å´©æºƒ
			t.Logf("Successfully handled error case: %s", tt.name)
		})
	}
}

// TestLexerComplexDocument æµ‹è¯•å¤æ‚æ–‡æ¡£
func TestLexerComplexDocument(t *testing.T) {
	input := `<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<!-- This is a comment -->
<html lang="en">
	<head>
		<title>Test Document</title>
	</head>
	<body>
		<h1>Hello World</h1>
		<p>This is a <strong>test</strong> document.</p>
		<img src="image.jpg" alt="Test Image" />
	</body>
</html>`

	lexer := NewLexer(input)
	tokenCount := 0

	for {
		token := lexer.NextToken()
		tokenCount++

		// éªŒè¯æ¯ä¸ªtokenéƒ½æœ‰æœ‰æ•ˆçš„ä½ç½®ä¿¡æ¯
		if token.Position.Line < 1 || token.Position.Column < 1 {
			t.Errorf("invalid position for token %d: (%d,%d)", tokenCount, token.Position.Line, token.Position.Column)
		}

		if token.Type == TokenEOF {
			break
		}

		// é˜²æ­¢æ— é™å¾ªç¯
		if tokenCount > 100 {
			t.Fatal("too many tokens, possible infinite loop")
		}
	}

	if tokenCount < 10 {
		t.Errorf("expected more tokens for complex document, got %d", tokenCount)
	}
}

// TestLexerSelfClosingTags æµ‹è¯•è‡ªå°é—­æ ‡ç­¾
func TestLexerSelfClosingTags(t *testing.T) {
	// åˆ›å»ºå…è®¸è‡ªå°é—­æ ‡ç­¾çš„é…ç½®
	config := DefaultConfig()
	config.AllowSelfCloseTags = true

	tests := []struct {
		name     string
		input    string
		expected TokenType
	}{
		{
			name:     "Self-closing img tag",
			input:    "<img />",
			expected: TokenSelfCloseTag,
		},
		{
			name:     "Self-closing br tag",
			input:    "<br/>",
			expected: TokenSelfCloseTag,
		},
		{
			name:     "Self-closing input tag",
			input:    "<input type='text' />",
			expected: TokenSelfCloseTag,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			lexer := NewLexerWithConfig(tt.input, config)
			token := lexer.NextToken()

			if token.Type != tt.expected {
				t.Errorf("expected token type %v, got %v", tt.expected, token.Type)
			}
		})
	}
}

// TestLexerConfigurationEffects æµ‹è¯•é…ç½®å¯¹è¯æ³•åˆ†æçš„å½±å“
func TestLexerConfigurationEffects(t *testing.T) {
	input := "<img />"

	// æµ‹è¯•ä¸å…è®¸è‡ªå°é—­æ ‡ç­¾çš„é…ç½®
	configNoSelfClose := DefaultConfig()
	configNoSelfClose.AllowSelfCloseTags = false

	lexer := NewLexerWithConfig(input, configNoSelfClose)
	token := lexer.NextToken()

	// åº”è¯¥è¿”å›é”™è¯¯token
	if token.Type != TokenError {
		t.Errorf("expected error token when self-closing tags disabled, got %v", token.Type)
	}

	// æµ‹è¯•å…è®¸è‡ªå°é—­æ ‡ç­¾çš„é…ç½®
	configAllowSelfClose := DefaultConfig()
	configAllowSelfClose.AllowSelfCloseTags = true

	lexer = NewLexerWithConfig(input, configAllowSelfClose)
	token = lexer.NextToken()

	// åº”è¯¥è¿”å›è‡ªå°é—­æ ‡ç­¾token
	if token.Type != TokenSelfCloseTag {
		t.Errorf("expected self-close tag token when enabled, got %v", token.Type)
	}
}
